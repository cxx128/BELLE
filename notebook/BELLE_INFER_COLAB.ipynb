{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ** BELLE模型在COLAB推理的示例** \n",
        "这里提供在colab环境运行BELLE模型的代码。需要注意的是，为了保证模型的正常加载，需要选择Runtime->Change Runtime type->Runtime shape->High RAM,只有这样才能将模型先加载到内存中，在模型加载到内存过程中，最高消费RAM大概需要16G，等模型load到GPU中以后，RAM只需要4G，GPU大概需要11G。\n"
      ],
      "metadata": {
        "id": "p70s1UElROWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 查看colab分配的显卡类型，一般免费账户上14G的T4显卡"
      ],
      "metadata": {
        "id": "QUt9JenaRViP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ORaFqtT6QV4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLwfc3zuPqmK",
        "outputId": "16938dac-32e5-4f65-c75b-792c782bc9d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr  5 12:30:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  将BELLE项目git clone到colab"
      ],
      "metadata": {
        "id": "w8ZvOYEKRl-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LianjiaTech/BELLE.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zSYeftDDS3l",
        "outputId": "330006af-a3f6-489b-e0ea-d2cb521043d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BELLE' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14G显卡目前只支持量化版本，这里暂时只提供量化版本在colab推理"
      ],
      "metadata": {
        "id": "5u8KiaitR3Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd BELLE/gptq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEzcL3t7DkAW",
        "outputId": "3e3b2e51-5c62-4ec6-e567-b578077641ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BELLE/gptq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 安装gptq环境"
      ],
      "metadata": {
        "id": "QpGt4F3BSLW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd9frauTDx8t",
        "outputId": "cd0f929f-dea5-4201-a33c-54ea335a1d6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/',\n",
              " 'Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 4))',\n",
              " '  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-w063dz_m',\n",
              " '  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-w063dz_m',\n",
              " '  Resolved https://github.com/huggingface/transformers to commit 2a91a9ef663776ad8259ff22fd285f3cfc888d0f',\n",
              " '  Installing build dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Getting requirements to build wheel ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Installing backend dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Preparing metadata (pyproject.toml) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " 'Requirement already satisfied: safetensors==0.3.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (0.3.0)',\n",
              " 'Requirement already satisfied: datasets==2.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (2.10.1)',\n",
              " 'Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.1.97)',\n",
              " 'Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (23.0)',\n",
              " 'Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (9.0.0)',\n",
              " 'Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (4.65.0)',\n",
              " 'Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.13.3)',\n",
              " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (6.0)',\n",
              " 'Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (3.8.4)',\n",
              " 'Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.3.6)',\n",
              " 'Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (1.4.4)',\n",
              " 'Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2.27.1)',\n",
              " 'Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (1.22.4)',\n",
              " 'Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.70.14)',\n",
              " 'Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (3.2.0)',\n",
              " 'Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.18.0)',\n",
              " 'Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2023.3.0)',\n",
              " 'Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 4)) (2022.10.31)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 4)) (3.10.7)',\n",
              " 'Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 4)) (0.13.3)',\n",
              " 'Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (2.0.12)',\n",
              " 'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.3.3)',\n",
              " 'Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.3.1)',\n",
              " 'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (6.0.4)',\n",
              " 'Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.8.2)',\n",
              " 'Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (4.0.2)',\n",
              " 'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (22.2.0)',\n",
              " 'Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1->-r requirements.txt (line 2)) (4.5.0)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (3.4)',\n",
              " 'Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (1.26.15)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (2022.12.7)',\n",
              " 'Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2.8.2)',\n",
              " 'Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2022.7.1)',\n",
              " 'Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.10.1->-r requirements.txt (line 2)) (1.16.0)']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python setup_cuda.py install && CUDA_VISIBLE_DEVICES=0 && python test_kernel.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT0Gq7tkEWs6",
        "outputId": "854ba2b8-1e8d-45ec-b8f8-164ee3e79f48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing quant_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to quant_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to quant_cuda.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'quant_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'quant_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.9/quant_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for quant_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/quant_cuda.py to quant_cuda.cpython-39.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.quant_cuda.cpython-39: module references __file__\n",
            "creating 'dist/quant_cuda-0.0.0-py3.9-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing quant_cuda-0.0.0-py3.9-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.9/dist-packages/quant_cuda-0.0.0-py3.9-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.9/dist-packages/quant_cuda-0.0.0-py3.9-linux-x86_64.egg\n",
            "Extracting quant_cuda-0.0.0-py3.9-linux-x86_64.egg to /usr/local/lib/python3.9/dist-packages\n",
            "quant-cuda 0.0.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/quant_cuda-0.0.0-py3.9-linux-x86_64.egg\n",
            "Processing dependencies for quant-cuda==0.0.0\n",
            "Finished processing dependencies for quant-cuda==0.0.0\n",
            "Benchmarking LLaMa-7B FC2 matvec ...\n",
            "FP16: 0.000746342658996582\n",
            "2bit: 0.0011006524562835692\n",
            "3bit: 0.0008499970436096192\n",
            "4bit: 0.0007870781421661377\n",
            "8bit: 0.0006487221717834473\n",
            "Verifiying kernel correctness ...\n",
            "2bit Simu: tensor([[[ 6.9198e-01,  8.5521e-01, -1.6247e+00,  ..., -3.2857e-01,\n",
            "          -2.2311e-01, -2.8462e-01],\n",
            "         [-8.9118e-02,  4.3766e-01,  1.6412e-01,  ...,  2.4427e-01,\n",
            "           3.1767e-01,  1.6467e-01],\n",
            "         [-1.3740e-02,  7.5172e-01, -6.6090e-02,  ..., -2.0919e-02,\n",
            "           1.5461e-01,  5.8638e-01],\n",
            "         ...,\n",
            "         [-1.2875e+00,  2.5620e-01, -6.0287e-01,  ...,  1.2245e+00,\n",
            "          -1.8057e-02,  6.7870e-01],\n",
            "         [-3.7346e-01,  3.4354e-01,  9.9958e-04,  ...,  8.9251e-02,\n",
            "           1.9225e-01,  2.7059e-01],\n",
            "         [ 7.8206e-01, -5.4750e-01,  2.3736e-01,  ...,  3.4987e-01,\n",
            "           4.0608e-01, -1.8804e-01]],\n",
            "\n",
            "        [[-5.1945e-01, -6.4797e-01, -3.6192e-01,  ...,  5.2366e-02,\n",
            "          -1.3986e-01, -3.5500e-01],\n",
            "         [-7.6479e-01,  5.8981e-01, -2.8219e-01,  ..., -2.7865e-01,\n",
            "          -9.8515e-01,  7.9422e-01],\n",
            "         [-5.6674e-01,  3.0916e-01, -1.7061e-01,  ..., -6.2503e-01,\n",
            "          -1.7449e-01, -7.9373e-01],\n",
            "         ...,\n",
            "         [ 5.8008e-01, -3.6582e-01,  9.0270e-02,  ...,  4.8310e-02,\n",
            "          -2.3756e-01,  1.0374e+00],\n",
            "         [-3.7805e-01, -8.2362e-01, -2.8786e-01,  ...,  4.5250e-01,\n",
            "           1.3549e-01,  3.8366e-01],\n",
            "         [-3.0067e-02,  4.3086e-01,  1.5670e-01,  ..., -4.7585e-01,\n",
            "          -3.8352e-01, -1.4725e-01]],\n",
            "\n",
            "        [[-5.9073e-01,  8.3945e-01, -1.7013e-01,  ..., -1.5190e-01,\n",
            "          -4.0897e-01, -1.5233e-01],\n",
            "         [-2.4717e-01, -1.8753e-01,  7.5616e-03,  ..., -3.0929e-01,\n",
            "           5.4834e-01,  5.9805e-01],\n",
            "         [ 7.6021e-01,  2.2352e-01, -7.3350e-01,  ..., -3.7972e-01,\n",
            "           2.9134e-01, -3.3625e-01],\n",
            "         ...,\n",
            "         [-4.2987e-01,  7.4488e-02,  2.5971e-01,  ...,  6.1169e-01,\n",
            "          -3.2958e-01,  5.1830e-01],\n",
            "         [-5.5219e-01, -5.6797e-01,  3.1215e-01,  ...,  2.5314e-01,\n",
            "           7.3797e-01, -2.5696e-01],\n",
            "         [ 4.8565e-01, -1.7771e-01,  6.8703e-02,  ...,  6.1020e-01,\n",
            "           1.7589e-01,  4.9162e-02]],\n",
            "\n",
            "        [[-4.2205e-01,  3.9951e-01, -7.6245e-01,  ...,  1.8323e-01,\n",
            "          -8.3835e-01, -2.3621e-01],\n",
            "         [ 3.0040e-01, -4.2516e-01, -8.0040e-01,  ..., -8.2551e-01,\n",
            "           1.9041e-01,  2.7233e-01],\n",
            "         [ 4.7757e-01, -2.7747e-01, -5.1023e-01,  ..., -3.0174e-01,\n",
            "          -6.6574e-01, -4.0739e-01],\n",
            "         ...,\n",
            "         [ 1.0598e+00, -6.7184e-01,  9.6148e-01,  ..., -4.2766e-01,\n",
            "           7.8591e-01, -8.3473e-01],\n",
            "         [ 8.8764e-01,  4.9371e-01, -5.9368e-01,  ..., -1.2369e-01,\n",
            "          -1.7810e-01, -4.1216e-01],\n",
            "         [ 4.1585e-01, -1.0155e+00, -6.6183e-01,  ...,  3.6388e-01,\n",
            "           6.5370e-01, -6.4345e-01]],\n",
            "\n",
            "        [[-1.1144e+00, -3.8744e-01, -2.3281e-01,  ..., -3.9729e-01,\n",
            "           4.7419e-01, -3.2415e-01],\n",
            "         [-1.3152e+00, -1.5686e-02, -1.5404e-01,  ...,  9.0517e-02,\n",
            "           2.1970e-01,  3.2548e-01],\n",
            "         [-8.2612e-02,  7.7289e-01,  2.5630e-02,  ..., -2.5077e-01,\n",
            "          -5.5296e-02, -4.4580e-01],\n",
            "         ...,\n",
            "         [ 3.7399e-01,  3.1102e-02, -3.5879e-01,  ...,  5.4255e-01,\n",
            "          -1.1654e-01, -6.8352e-01],\n",
            "         [-7.0670e-02, -2.3322e-01, -3.4047e-01,  ..., -1.4104e-01,\n",
            "          -6.1207e-02, -4.3377e-01],\n",
            "         [ 1.9063e-01, -1.6342e-01,  5.6445e-01,  ...,  1.6025e-01,\n",
            "          -1.8971e-01, -7.9114e-01]]], device='cuda:0')\n",
            "2bit Kern: tensor([[[ 6.9198e-01,  8.5521e-01, -1.6247e+00,  ..., -3.2857e-01,\n",
            "          -2.2311e-01, -2.8462e-01],\n",
            "         [-8.9118e-02,  4.3766e-01,  1.6412e-01,  ...,  2.4427e-01,\n",
            "           3.1767e-01,  1.6467e-01],\n",
            "         [-1.3740e-02,  7.5172e-01, -6.6090e-02,  ..., -2.0919e-02,\n",
            "           1.5461e-01,  5.8638e-01],\n",
            "         ...,\n",
            "         [-1.2875e+00,  2.5620e-01, -6.0287e-01,  ...,  1.2245e+00,\n",
            "          -1.8057e-02,  6.7870e-01],\n",
            "         [-3.7346e-01,  3.4354e-01,  9.9874e-04,  ...,  8.9251e-02,\n",
            "           1.9225e-01,  2.7059e-01],\n",
            "         [ 7.8206e-01, -5.4750e-01,  2.3736e-01,  ...,  3.4987e-01,\n",
            "           4.0608e-01, -1.8804e-01]],\n",
            "\n",
            "        [[-5.1945e-01, -6.4797e-01, -3.6192e-01,  ...,  5.2366e-02,\n",
            "          -1.3986e-01, -3.5500e-01],\n",
            "         [-7.6478e-01,  5.8981e-01, -2.8219e-01,  ..., -2.7865e-01,\n",
            "          -9.8515e-01,  7.9422e-01],\n",
            "         [-5.6674e-01,  3.0916e-01, -1.7061e-01,  ..., -6.2504e-01,\n",
            "          -1.7449e-01, -7.9373e-01],\n",
            "         ...,\n",
            "         [ 5.8008e-01, -3.6582e-01,  9.0271e-02,  ...,  4.8309e-02,\n",
            "          -2.3756e-01,  1.0374e+00],\n",
            "         [-3.7805e-01, -8.2362e-01, -2.8786e-01,  ...,  4.5250e-01,\n",
            "           1.3549e-01,  3.8366e-01],\n",
            "         [-3.0067e-02,  4.3086e-01,  1.5670e-01,  ..., -4.7585e-01,\n",
            "          -3.8352e-01, -1.4725e-01]],\n",
            "\n",
            "        [[-5.9074e-01,  8.3945e-01, -1.7013e-01,  ..., -1.5190e-01,\n",
            "          -4.0897e-01, -1.5233e-01],\n",
            "         [-2.4717e-01, -1.8753e-01,  7.5618e-03,  ..., -3.0929e-01,\n",
            "           5.4834e-01,  5.9805e-01],\n",
            "         [ 7.6021e-01,  2.2352e-01, -7.3351e-01,  ..., -3.7972e-01,\n",
            "           2.9134e-01, -3.3625e-01],\n",
            "         ...,\n",
            "         [-4.2987e-01,  7.4488e-02,  2.5971e-01,  ...,  6.1169e-01,\n",
            "          -3.2958e-01,  5.1830e-01],\n",
            "         [-5.5219e-01, -5.6797e-01,  3.1215e-01,  ...,  2.5314e-01,\n",
            "           7.3797e-01, -2.5696e-01],\n",
            "         [ 4.8565e-01, -1.7771e-01,  6.8703e-02,  ...,  6.1020e-01,\n",
            "           1.7589e-01,  4.9161e-02]],\n",
            "\n",
            "        [[-4.2205e-01,  3.9951e-01, -7.6245e-01,  ...,  1.8322e-01,\n",
            "          -8.3835e-01, -2.3621e-01],\n",
            "         [ 3.0040e-01, -4.2516e-01, -8.0040e-01,  ..., -8.2551e-01,\n",
            "           1.9041e-01,  2.7233e-01],\n",
            "         [ 4.7758e-01, -2.7747e-01, -5.1023e-01,  ..., -3.0174e-01,\n",
            "          -6.6574e-01, -4.0739e-01],\n",
            "         ...,\n",
            "         [ 1.0598e+00, -6.7184e-01,  9.6148e-01,  ..., -4.2766e-01,\n",
            "           7.8591e-01, -8.3473e-01],\n",
            "         [ 8.8764e-01,  4.9371e-01, -5.9368e-01,  ..., -1.2369e-01,\n",
            "          -1.7810e-01, -4.1216e-01],\n",
            "         [ 4.1585e-01, -1.0155e+00, -6.6183e-01,  ...,  3.6388e-01,\n",
            "           6.5370e-01, -6.4344e-01]],\n",
            "\n",
            "        [[-1.1144e+00, -3.8744e-01, -2.3281e-01,  ..., -3.9729e-01,\n",
            "           4.7419e-01, -3.2415e-01],\n",
            "         [-1.3152e+00, -1.5686e-02, -1.5404e-01,  ...,  9.0517e-02,\n",
            "           2.1970e-01,  3.2548e-01],\n",
            "         [-8.2612e-02,  7.7289e-01,  2.5631e-02,  ..., -2.5077e-01,\n",
            "          -5.5297e-02, -4.4580e-01],\n",
            "         ...,\n",
            "         [ 3.7399e-01,  3.1101e-02, -3.5879e-01,  ...,  5.4255e-01,\n",
            "          -1.1654e-01, -6.8352e-01],\n",
            "         [-7.0669e-02, -2.3321e-01, -3.4047e-01,  ..., -1.4104e-01,\n",
            "          -6.1207e-02, -4.3377e-01],\n",
            "         [ 1.9063e-01, -1.6342e-01,  5.6445e-01,  ...,  1.6025e-01,\n",
            "          -1.8971e-01, -7.9114e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "3bit Simu: tensor([[[-1.0115,  0.5440, -0.0921,  ...,  0.6694, -0.1270, -0.6056],\n",
            "         [-0.6006, -0.3226, -0.5526,  ..., -0.6183, -0.0469,  0.2265],\n",
            "         [-0.0531, -0.3089,  0.5595,  ...,  0.4077, -0.2532, -0.1546],\n",
            "         ...,\n",
            "         [-0.0647,  0.3725,  0.2391,  ..., -0.0902, -0.5202, -0.9972],\n",
            "         [-1.2452, -0.1038,  0.7639,  ...,  0.4020,  0.3546,  0.2693],\n",
            "         [ 0.8870,  0.1930,  0.7734,  ..., -0.2715,  0.3849,  0.7794]],\n",
            "\n",
            "        [[-0.3522,  0.3784,  0.6764,  ...,  0.3059, -0.0228, -0.6224],\n",
            "         [-0.0528,  0.5247,  0.2441,  ..., -0.4598,  0.0812, -0.5418],\n",
            "         [-1.0290,  0.4578, -0.1196,  ...,  0.2689, -0.3693, -0.1269],\n",
            "         ...,\n",
            "         [-0.2345, -0.3697, -0.3406,  ...,  0.2326,  0.5656, -0.5931],\n",
            "         [-0.2475, -0.0425, -0.0170,  ...,  0.4513,  0.4860,  0.6368],\n",
            "         [-0.5609, -0.4425, -0.2773,  ...,  0.6961,  0.1550,  0.6152]],\n",
            "\n",
            "        [[-0.1127,  0.2246, -0.5157,  ...,  0.1172, -0.3338, -0.5505],\n",
            "         [-0.0641, -0.8498, -0.6178,  ...,  0.2291, -0.9050,  0.0638],\n",
            "         [-1.0389, -0.8636, -0.3580,  ...,  0.6525,  0.7895,  0.5166],\n",
            "         ...,\n",
            "         [-0.2521, -0.4117,  0.2549,  ..., -0.1910,  0.4494, -0.3154],\n",
            "         [-0.5475, -0.5624, -0.3668,  ...,  0.0187,  0.1790,  0.4848],\n",
            "         [ 0.4860, -0.0442,  0.2503,  ...,  1.4630,  0.7750,  0.1437]],\n",
            "\n",
            "        [[-0.0636,  1.2752, -0.0947,  ...,  0.0837, -0.5155, -0.7413],\n",
            "         [ 1.1678, -0.5066, -0.3362,  ..., -0.3725, -1.1728,  0.1485],\n",
            "         [ 0.8066, -0.5909,  0.0243,  ..., -0.0407,  0.5470,  0.1730],\n",
            "         ...,\n",
            "         [ 0.1865, -0.1192, -0.5134,  ..., -0.3153,  0.0995, -0.2852],\n",
            "         [ 0.0993,  0.0077, -0.4463,  ...,  0.0768,  1.1047, -0.3624],\n",
            "         [ 0.4892, -0.5238,  0.9830,  ..., -0.6211,  0.4370,  1.0144]],\n",
            "\n",
            "        [[ 0.3659,  0.5164, -0.5577,  ...,  0.4631,  0.2097,  0.2002],\n",
            "         [-0.2300,  0.7890, -0.1492,  ..., -0.1609,  0.4687,  0.0146],\n",
            "         [ 0.6995, -0.0752, -0.3823,  ..., -0.1107, -0.8758,  0.4405],\n",
            "         ...,\n",
            "         [ 0.1553,  0.2099, -0.4263,  ..., -0.2348, -0.3935, -0.0247],\n",
            "         [ 0.4001,  0.1561,  0.4754,  ...,  1.2441, -0.4489,  0.9354],\n",
            "         [-0.3444,  0.4839, -0.1220,  ..., -0.3274, -0.8847, -0.3549]]],\n",
            "       device='cuda:0')\n",
            "3bit Kern: tensor([[[-1.0115,  0.5440, -0.0921,  ...,  0.6694, -0.1270, -0.6056],\n",
            "         [-0.6006, -0.3226, -0.5526,  ..., -0.6183, -0.0469,  0.2265],\n",
            "         [-0.0531, -0.3089,  0.5595,  ...,  0.4077, -0.2532, -0.1546],\n",
            "         ...,\n",
            "         [-0.0647,  0.3725,  0.2391,  ..., -0.0902, -0.5202, -0.9972],\n",
            "         [-1.2452, -0.1038,  0.7639,  ...,  0.4020,  0.3546,  0.2693],\n",
            "         [ 0.8870,  0.1930,  0.7734,  ..., -0.2715,  0.3849,  0.7794]],\n",
            "\n",
            "        [[-0.3522,  0.3784,  0.6764,  ...,  0.3059, -0.0228, -0.6224],\n",
            "         [-0.0528,  0.5247,  0.2441,  ..., -0.4598,  0.0812, -0.5418],\n",
            "         [-1.0290,  0.4578, -0.1196,  ...,  0.2689, -0.3693, -0.1269],\n",
            "         ...,\n",
            "         [-0.2345, -0.3697, -0.3406,  ...,  0.2326,  0.5656, -0.5931],\n",
            "         [-0.2475, -0.0425, -0.0170,  ...,  0.4513,  0.4860,  0.6368],\n",
            "         [-0.5609, -0.4425, -0.2773,  ...,  0.6961,  0.1550,  0.6152]],\n",
            "\n",
            "        [[-0.1127,  0.2246, -0.5157,  ...,  0.1172, -0.3338, -0.5505],\n",
            "         [-0.0641, -0.8498, -0.6178,  ...,  0.2291, -0.9050,  0.0638],\n",
            "         [-1.0389, -0.8636, -0.3580,  ...,  0.6525,  0.7895,  0.5166],\n",
            "         ...,\n",
            "         [-0.2521, -0.4117,  0.2549,  ..., -0.1910,  0.4494, -0.3154],\n",
            "         [-0.5475, -0.5624, -0.3668,  ...,  0.0187,  0.1790,  0.4848],\n",
            "         [ 0.4860, -0.0442,  0.2503,  ...,  1.4630,  0.7750,  0.1437]],\n",
            "\n",
            "        [[-0.0636,  1.2752, -0.0947,  ...,  0.0837, -0.5155, -0.7413],\n",
            "         [ 1.1678, -0.5066, -0.3362,  ..., -0.3725, -1.1728,  0.1485],\n",
            "         [ 0.8066, -0.5909,  0.0243,  ..., -0.0407,  0.5470,  0.1730],\n",
            "         ...,\n",
            "         [ 0.1865, -0.1192, -0.5134,  ..., -0.3153,  0.0995, -0.2852],\n",
            "         [ 0.0993,  0.0077, -0.4463,  ...,  0.0768,  1.1047, -0.3624],\n",
            "         [ 0.4892, -0.5238,  0.9830,  ..., -0.6211,  0.4370,  1.0144]],\n",
            "\n",
            "        [[ 0.3659,  0.5164, -0.5577,  ...,  0.4631,  0.2097,  0.2002],\n",
            "         [-0.2300,  0.7890, -0.1492,  ..., -0.1609,  0.4687,  0.0146],\n",
            "         [ 0.6995, -0.0752, -0.3823,  ..., -0.1107, -0.8758,  0.4405],\n",
            "         ...,\n",
            "         [ 0.1553,  0.2099, -0.4263,  ..., -0.2348, -0.3935, -0.0247],\n",
            "         [ 0.4001,  0.1561,  0.4754,  ...,  1.2441, -0.4489,  0.9354],\n",
            "         [-0.3444,  0.4839, -0.1220,  ..., -0.3274, -0.8847, -0.3549]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "4bit Simu: tensor([[[ 0.8274,  0.0520,  0.2401,  ..., -0.6067,  0.0478, -0.3601],\n",
            "         [-0.2896,  0.1893, -0.0828,  ...,  0.8454,  0.1121,  0.5271],\n",
            "         [-0.4108,  0.2259, -0.7418,  ..., -0.9588,  0.2621, -0.6404],\n",
            "         ...,\n",
            "         [ 0.6586, -0.1714, -0.0269,  ..., -0.2297, -0.5800, -0.4797],\n",
            "         [-0.7497, -0.1555, -0.2715,  ...,  0.3946,  0.2594, -0.1920],\n",
            "         [ 0.5234,  1.4144, -0.1689,  ..., -0.5322,  1.2460, -0.4745]],\n",
            "\n",
            "        [[-0.3418, -0.3753, -0.5073,  ...,  0.4229,  0.5604, -0.4011],\n",
            "         [ 0.8188,  0.0893,  0.1826,  ...,  0.0142, -1.1723, -0.7225],\n",
            "         [ 0.5060,  0.1868,  0.1265,  ...,  0.6760, -0.1583, -0.7287],\n",
            "         ...,\n",
            "         [-0.5221,  0.1914,  1.1855,  ..., -0.2962,  0.9117,  0.1849],\n",
            "         [ 1.1785, -0.4038,  0.3496,  ...,  0.1227,  0.0332, -1.1618],\n",
            "         [ 0.6736, -0.4986, -0.6261,  ..., -0.0426,  0.9161,  0.1044]],\n",
            "\n",
            "        [[-0.4881,  1.3302, -0.5357,  ...,  0.1530,  0.2318, -1.3368],\n",
            "         [-0.3160,  0.2938, -0.3856,  ..., -0.4343,  1.1474, -0.2884],\n",
            "         [ 0.1831,  0.4031,  0.1388,  ..., -0.5823, -0.0144,  0.2078],\n",
            "         ...,\n",
            "         [-0.5554, -0.2222,  0.4972,  ..., -0.8827,  0.5198, -0.7973],\n",
            "         [-0.3271,  0.4814, -0.1766,  ...,  0.0110,  0.4466,  0.3983],\n",
            "         [ 0.5767, -0.5110,  0.0288,  ..., -1.4895, -0.2096, -0.0436]],\n",
            "\n",
            "        [[-0.6453,  0.6556,  0.8389,  ...,  0.4096, -1.0311,  0.9209],\n",
            "         [ 0.0223, -0.0661,  0.4556,  ..., -0.0505, -0.0818, -0.0766],\n",
            "         [-0.1875,  0.6293,  0.1126,  ..., -0.1779, -0.1869,  0.2147],\n",
            "         ...,\n",
            "         [ 1.1322, -0.6943,  0.0404,  ...,  0.4438,  0.2566,  0.2742],\n",
            "         [ 0.1547, -0.3707,  0.3499,  ...,  0.7467, -0.7197, -0.3853],\n",
            "         [ 0.2499,  0.7077, -0.5468,  ...,  0.5787,  0.5094,  0.2601]],\n",
            "\n",
            "        [[ 0.5567, -0.0771,  0.3696,  ..., -1.0058, -0.4435, -0.2902],\n",
            "         [ 1.0851, -0.3756,  0.0091,  ...,  0.3057, -0.2484,  0.7646],\n",
            "         [-0.5532,  0.4169,  0.6847,  ...,  0.3294,  0.4931,  0.4176],\n",
            "         ...,\n",
            "         [-0.4966,  0.3353,  0.4398,  ...,  0.5180,  0.5139,  0.9836],\n",
            "         [-1.0123, -0.0862,  0.0261,  ...,  0.1823, -1.0788,  0.3636],\n",
            "         [ 0.6199, -0.0720, -0.9568,  ...,  0.3299, -0.2685,  0.6702]]],\n",
            "       device='cuda:0')\n",
            "4bit Kern: tensor([[[ 0.8274,  0.0520,  0.2401,  ..., -0.6067,  0.0478, -0.3601],\n",
            "         [-0.2896,  0.1893, -0.0828,  ...,  0.8454,  0.1121,  0.5271],\n",
            "         [-0.4108,  0.2259, -0.7418,  ..., -0.9588,  0.2621, -0.6404],\n",
            "         ...,\n",
            "         [ 0.6586, -0.1714, -0.0269,  ..., -0.2297, -0.5800, -0.4797],\n",
            "         [-0.7497, -0.1555, -0.2715,  ...,  0.3946,  0.2594, -0.1920],\n",
            "         [ 0.5234,  1.4144, -0.1689,  ..., -0.5322,  1.2460, -0.4745]],\n",
            "\n",
            "        [[-0.3418, -0.3753, -0.5073,  ...,  0.4229,  0.5604, -0.4011],\n",
            "         [ 0.8188,  0.0893,  0.1826,  ...,  0.0142, -1.1724, -0.7225],\n",
            "         [ 0.5060,  0.1868,  0.1265,  ...,  0.6760, -0.1583, -0.7287],\n",
            "         ...,\n",
            "         [-0.5221,  0.1914,  1.1855,  ..., -0.2962,  0.9117,  0.1849],\n",
            "         [ 1.1785, -0.4038,  0.3496,  ...,  0.1227,  0.0332, -1.1618],\n",
            "         [ 0.6736, -0.4986, -0.6261,  ..., -0.0426,  0.9161,  0.1044]],\n",
            "\n",
            "        [[-0.4881,  1.3302, -0.5357,  ...,  0.1530,  0.2318, -1.3368],\n",
            "         [-0.3160,  0.2938, -0.3856,  ..., -0.4343,  1.1474, -0.2884],\n",
            "         [ 0.1831,  0.4031,  0.1388,  ..., -0.5823, -0.0144,  0.2078],\n",
            "         ...,\n",
            "         [-0.5554, -0.2222,  0.4972,  ..., -0.8827,  0.5198, -0.7973],\n",
            "         [-0.3271,  0.4814, -0.1766,  ...,  0.0110,  0.4466,  0.3983],\n",
            "         [ 0.5767, -0.5110,  0.0288,  ..., -1.4895, -0.2096, -0.0436]],\n",
            "\n",
            "        [[-0.6453,  0.6556,  0.8389,  ...,  0.4096, -1.0311,  0.9209],\n",
            "         [ 0.0223, -0.0661,  0.4556,  ..., -0.0505, -0.0818, -0.0766],\n",
            "         [-0.1875,  0.6293,  0.1126,  ..., -0.1779, -0.1869,  0.2147],\n",
            "         ...,\n",
            "         [ 1.1322, -0.6943,  0.0404,  ...,  0.4438,  0.2566,  0.2742],\n",
            "         [ 0.1547, -0.3707,  0.3499,  ...,  0.7467, -0.7197, -0.3853],\n",
            "         [ 0.2499,  0.7077, -0.5468,  ...,  0.5787,  0.5094,  0.2601]],\n",
            "\n",
            "        [[ 0.5567, -0.0771,  0.3696,  ..., -1.0058, -0.4435, -0.2902],\n",
            "         [ 1.0851, -0.3756,  0.0091,  ...,  0.3057, -0.2484,  0.7646],\n",
            "         [-0.5532,  0.4169,  0.6846,  ...,  0.3294,  0.4931,  0.4176],\n",
            "         ...,\n",
            "         [-0.4966,  0.3353,  0.4398,  ...,  0.5180,  0.5139,  0.9836],\n",
            "         [-1.0123, -0.0862,  0.0261,  ...,  0.1823, -1.0788,  0.3636],\n",
            "         [ 0.6199, -0.0720, -0.9568,  ...,  0.3299, -0.2685,  0.6702]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "\n",
            "8bit Simu: tensor([[[-0.3004,  0.3509, -0.2102,  ...,  0.2589,  0.1993, -0.4678],\n",
            "         [-0.3055, -0.1721,  0.1284,  ..., -0.1945,  0.0801,  0.2713],\n",
            "         [ 0.6596,  0.7803, -0.3332,  ...,  0.3196,  0.2400, -0.0087],\n",
            "         ...,\n",
            "         [ 0.9523,  0.0922, -0.4928,  ...,  0.0231, -1.1176, -0.9493],\n",
            "         [ 0.2597, -0.6735,  0.3457,  ..., -0.1222,  0.8683, -0.2391],\n",
            "         [-0.3170, -0.6467, -0.6601,  ..., -0.0866, -0.1905, -0.1110]],\n",
            "\n",
            "        [[ 0.1482, -0.5084, -0.1183,  ..., -0.1224, -0.5458, -0.2863],\n",
            "         [ 0.4326, -0.5840, -1.0022,  ..., -0.6310, -0.3959,  0.3937],\n",
            "         [ 0.9301,  0.9593, -0.0071,  ...,  0.0660,  0.3140,  0.6003],\n",
            "         ...,\n",
            "         [ 0.2308, -0.2758, -0.2793,  ..., -0.8507, -0.7454,  0.4034],\n",
            "         [ 0.3144,  0.3681, -0.0754,  ..., -0.9695,  0.8676, -0.0218],\n",
            "         [-0.0363, -0.8464, -0.3488,  ..., -0.1632,  0.1254,  0.8246]],\n",
            "\n",
            "        [[-0.1037, -0.1702, -0.1140,  ..., -0.2626, -0.4562,  0.4192],\n",
            "         [ 0.1208,  0.5848,  0.0991,  ...,  0.1754,  0.0409,  0.0355],\n",
            "         [-0.4774,  0.7962,  0.9518,  ...,  0.4453,  0.8441,  0.6480],\n",
            "         ...,\n",
            "         [ 0.1056, -0.0043,  0.1780,  ..., -0.5053, -0.5592,  0.1121],\n",
            "         [-0.6670,  0.2603,  0.6213,  ..., -1.7264, -0.8012,  0.7429],\n",
            "         [ 0.0299,  0.0561,  0.8886,  ...,  0.7904,  0.3316, -0.7483]],\n",
            "\n",
            "        [[ 0.5541, -0.3273, -0.3688,  ...,  0.1049, -1.8890, -1.1443],\n",
            "         [ 0.0226, -0.0196,  1.5917,  ...,  0.4220,  0.0302, -0.2799],\n",
            "         [-0.7378,  0.2251,  0.1136,  ...,  0.4324, -0.5542, -0.1202],\n",
            "         ...,\n",
            "         [ 0.0852, -0.2968,  0.1917,  ...,  0.4076,  0.8171, -0.1996],\n",
            "         [-0.1100,  0.5365,  0.8001,  ...,  0.5190, -0.6890, -0.3736],\n",
            "         [ 1.4950,  0.5658,  0.3490,  ..., -0.0214, -0.7861,  0.2827]],\n",
            "\n",
            "        [[-0.4680,  1.3845,  0.0634,  ...,  0.8785, -0.5923, -0.1047],\n",
            "         [-0.8787, -0.8601,  0.7783,  ...,  0.0257, -0.0542,  0.2440],\n",
            "         [-0.1346,  0.2054, -0.1750,  ...,  1.3891, -1.0434,  0.3441],\n",
            "         ...,\n",
            "         [-0.2388,  0.1454,  0.2790,  ...,  0.1721, -0.0592, -0.0071],\n",
            "         [-0.1294,  0.5585,  0.9888,  ...,  1.4645,  0.0436, -0.5443],\n",
            "         [ 0.3520, -1.4049, -0.3163,  ..., -0.0349,  0.1593,  1.0462]]],\n",
            "       device='cuda:0')\n",
            "8bit Kern: tensor([[[-0.3004,  0.3509, -0.2102,  ...,  0.2589,  0.1993, -0.4678],\n",
            "         [-0.3055, -0.1721,  0.1284,  ..., -0.1945,  0.0801,  0.2713],\n",
            "         [ 0.6596,  0.7803, -0.3332,  ...,  0.3196,  0.2400, -0.0087],\n",
            "         ...,\n",
            "         [ 0.9523,  0.0922, -0.4928,  ...,  0.0231, -1.1176, -0.9493],\n",
            "         [ 0.2597, -0.6735,  0.3457,  ..., -0.1222,  0.8683, -0.2391],\n",
            "         [-0.3170, -0.6467, -0.6601,  ..., -0.0866, -0.1905, -0.1110]],\n",
            "\n",
            "        [[ 0.1482, -0.5084, -0.1183,  ..., -0.1224, -0.5458, -0.2863],\n",
            "         [ 0.4326, -0.5840, -1.0022,  ..., -0.6310, -0.3959,  0.3937],\n",
            "         [ 0.9301,  0.9593, -0.0071,  ...,  0.0660,  0.3140,  0.6003],\n",
            "         ...,\n",
            "         [ 0.2308, -0.2758, -0.2793,  ..., -0.8507, -0.7454,  0.4034],\n",
            "         [ 0.3144,  0.3681, -0.0754,  ..., -0.9695,  0.8676, -0.0218],\n",
            "         [-0.0363, -0.8464, -0.3488,  ..., -0.1632,  0.1254,  0.8246]],\n",
            "\n",
            "        [[-0.1037, -0.1702, -0.1140,  ..., -0.2626, -0.4562,  0.4192],\n",
            "         [ 0.1208,  0.5848,  0.0991,  ...,  0.1754,  0.0409,  0.0355],\n",
            "         [-0.4774,  0.7962,  0.9518,  ...,  0.4453,  0.8441,  0.6480],\n",
            "         ...,\n",
            "         [ 0.1056, -0.0043,  0.1780,  ..., -0.5053, -0.5592,  0.1121],\n",
            "         [-0.6670,  0.2603,  0.6213,  ..., -1.7264, -0.8012,  0.7429],\n",
            "         [ 0.0299,  0.0561,  0.8886,  ...,  0.7904,  0.3316, -0.7483]],\n",
            "\n",
            "        [[ 0.5541, -0.3273, -0.3688,  ...,  0.1049, -1.8890, -1.1443],\n",
            "         [ 0.0226, -0.0196,  1.5917,  ...,  0.4220,  0.0302, -0.2799],\n",
            "         [-0.7378,  0.2251,  0.1136,  ...,  0.4324, -0.5542, -0.1202],\n",
            "         ...,\n",
            "         [ 0.0852, -0.2968,  0.1917,  ...,  0.4076,  0.8171, -0.1996],\n",
            "         [-0.1100,  0.5365,  0.8001,  ...,  0.5190, -0.6890, -0.3736],\n",
            "         [ 1.4950,  0.5658,  0.3490,  ..., -0.0214, -0.7861,  0.2827]],\n",
            "\n",
            "        [[-0.4680,  1.3845,  0.0634,  ...,  0.8785, -0.5923, -0.1047],\n",
            "         [-0.8787, -0.8601,  0.7783,  ...,  0.0257, -0.0542,  0.2440],\n",
            "         [-0.1346,  0.2054, -0.1750,  ...,  1.3891, -1.0434,  0.3441],\n",
            "         ...,\n",
            "         [-0.2388,  0.1454,  0.2790,  ...,  0.1721, -0.0592, -0.0071],\n",
            "         [-0.1294,  0.5585,  0.9888,  ...,  1.4645,  0.0436, -0.5443],\n",
            "         [ 0.3520, -1.4049, -0.3163,  ..., -0.0349,  0.1593,  1.0462]]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 将BELLE-7B-gptq版本下载到colab\n"
      ],
      "metadata": {
        "id": "b0gYQ0aFSVTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git lfs install && git clone https://huggingface.co/BelleGroup/BELLE-7B-gptq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r0uotkjFjK8",
        "outputId": "8b4e8537-1469-4b5b-a61b-24fe1bce9867"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "fatal: destination path 'BELLE-7B-gptq' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls BELLE-7B-gptq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouZZilIOHr5Y",
        "outputId": "2b444ff8-298f-402d-e076-89d9b87344ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bloom7b-0.2m-4bit-128g.pt  bloom7b-2m-8bit-128g.pt  special_tokens_map.json\n",
            "bloom7b-0.2m-8bit-128g.pt  config.json\t\t    tokenizer_config.json\n",
            "bloom7b-2m-4bit-128g.pt    README.md\t\t    tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BELLE **gpqt推理**"
      ],
      "metadata": {
        "id": "XYKuTlQPSgIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from gptq import *\n",
        "from modelutils import *\n",
        "from quant import *\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "DEV = torch.device('cuda:0')\n",
        "\n",
        "def get_bloom(model):\n",
        "    import torch\n",
        "    def skip(*args, **kwargs):\n",
        "        pass\n",
        "    torch.nn.init.kaiming_uniform_ = skip\n",
        "    torch.nn.init.uniform_ = skip\n",
        "    torch.nn.init.normal_ = skip\n",
        "    from transformers import BloomForCausalLM\n",
        "    model = BloomForCausalLM.from_pretrained(model, torch_dtype='auto')\n",
        "    model.seqlen = 2048\n",
        "    return model\n",
        "\n",
        "def load_quant(model, checkpoint, wbits, groupsize):\n",
        "    from transformers import BloomConfig, BloomForCausalLM \n",
        "    config = BloomConfig.from_pretrained(model)\n",
        "    def noop(*args, **kwargs):\n",
        "        pass\n",
        "    torch.nn.init.kaiming_uniform_ = noop \n",
        "    torch.nn.init.uniform_ = noop \n",
        "    torch.nn.init.normal_ = noop \n",
        "\n",
        "    torch.set_default_dtype(torch.half)\n",
        "    transformers.modeling_utils._init_weights = False\n",
        "    torch.set_default_dtype(torch.half)\n",
        "    model = BloomForCausalLM(config)\n",
        "    torch.set_default_dtype(torch.float)\n",
        "    model = model.eval()\n",
        "    layers = find_layers(model)\n",
        "    for name in ['lm_head']:\n",
        "        if name in layers:\n",
        "            del layers[name]\n",
        "    make_quant(model, layers, wbits, groupsize)\n",
        "\n",
        "    print('Loading model ...')\n",
        "    if checkpoint.endswith('.safetensors'):\n",
        "        from safetensors.torch import load_file as safe_load\n",
        "        model.load_state_dict(safe_load(checkpoint))\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(checkpoint))\n",
        "    model.seqlen = 2048\n",
        "    print('Done.')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "class args:\n",
        "    model = \"BELLE-7B-gptq\"\n",
        "    wbits = 8\n",
        "    groupsize = 128\n",
        "    load = \"BELLE-7B-gptq/bloom7b-2m-8bit-128g.pt\"\n",
        "    text = None\n",
        "    min_length = 10\n",
        "    max_length = 1024\n",
        "    top_p = 0.95\n",
        "    temperature = 0.7\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "if type(args.load) is not str:\n",
        "    args.load = args.load.as_posix()\n",
        "\n",
        "if args.load:\n",
        "    model = load_quant(args.model, args.load, args.wbits, args.groupsize)\n",
        "else:\n",
        "    model = get_llama(args.model)\n",
        "    model.eval()\n",
        "\n",
        "model.to(DEV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq3Sch7NJDc4",
        "outputId": "d5156877-62ba-4bef-d33b-57f764082160"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model ...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BloomForCausalLM(\n",
              "  (transformer): BloomModel(\n",
              "    (word_embeddings): Embedding(250880, 4096)\n",
              "    (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "    (h): ModuleList(\n",
              "      (0-29): 30 x BloomBlock(\n",
              "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): BloomAttention(\n",
              "          (query_key_value): QuantLinear()\n",
              "          (dense): QuantLinear()\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): BloomMLP(\n",
              "          (dense_h_to_4h): QuantLinear()\n",
              "          (gelu_impl): BloomGelu()\n",
              "          (dense_4h_to_h): QuantLinear()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"BelleGroup/BELLE-7B-gptq\")\n"
      ],
      "metadata": {
        "id": "wEkYZgR2N5dm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_text_gen(text):\n",
        "    inputs = f'Human: {text} \\n\\nAssistant:'\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors=\"pt\").to(DEV)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=True,\n",
        "            min_length=args.min_length,\n",
        "            max_length=args.max_length,\n",
        "            top_p=args.top_p,\n",
        "            temperature=args.temperature,\n",
        "        )\n",
        "\n",
        "    decode_text = tokenizer.decode([el.item() for el in generated_ids[0]])\n",
        "    decode_text = decode_text[len(inputs):]\n",
        "    decode_text = decode_text.replace(\"</s>\",\"\")\n",
        "    return decode_text"
      ],
      "metadata": {
        "id": "YNk7kmfaOA3O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(infer_text_gen(\"你是谁？\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt822IK4OIpi",
        "outputId": "54f13cab-dff4-4598-eafd-51864c2650ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 我是一个人工智能语言模型，没有个人身份和意识。我的开发者们是来自全球各地的科学家和工程师。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(infer_text_gen(\"怎么让自己精力充沛，列5点建议\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuBIm4tcZ3yV",
        "outputId": "022a337e-9dbd-463a-ec87-1f4f22b63182"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. 规律作息：每天保持规律的作息时间，尽量在同一时间起床和睡觉，让身体和大脑能够适应这种规律。\n",
            "\n",
            "2. 锻炼身体：适当的体育锻炼能够让人充满活力，同时还能增强身体的免疫力。\n",
            "\n",
            "3. 合理饮食：保持健康的饮食习惯，摄入足够的营养物质，避免暴饮暴食和过多垃圾食品。\n",
            "\n",
            "4. 放松心情：遇到压力和焦虑时，可以通过冥想、瑜伽、按摩等方式放松心情，缓解压力。\n",
            "\n",
            "5. 保持良好的人际关系：和家人、朋友保持良好的关系，能够让人感到心情愉悦，并且能够提供支持和鼓励。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wno4FIAgZ8CI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}