unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 2, training_nums = 1985, num_steps = 992, warmup_steps = 1000, eval_steps = 124, save_steps = 124
world_size = 2
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 2, training_nums = 1985, num_steps = 992, warmup_steps = 1000, eval_steps = 124, save_steps = 124
world_size = 2
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [29871, 30810, 31882, 30630, 30210, 31900, 30548, 30214, 30810, 31882, 20778, 30210, 31969, 30745], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30417, 30287, 31893, 31900, 232, 146, 174, 232, 132, 157, 31811, 30413, 31174, 31475], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [29871, 30470, 235, 192, 190, 30594, 235, 144, 149, 31932, 234, 142, 133, 234, 134, 176, 31138, 30214, 30744, 30651, 31979, 30417, 31506, 30805, 30210, 233, 181, 140, 233, 186, 131, 30503, 31579, 235, 131, 134, 30267], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30287, 30346, 236, 155, 183, 233, 179, 151, 31076, 30908, 30210, 31900, 30267], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [29871, 30810, 31882, 30630, 30210, 31900, 30548, 30214, 30810, 31882, 20778, 30210, 31969, 30745], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30417, 30287, 31893, 31900, 232, 146, 174, 232, 132, 157, 31811, 30413, 31174, 31475], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [29871, 30470, 235, 192, 190, 30594, 235, 144, 149, 31932, 234, 142, 133, 234, 134, 176, 31138, 30214, 30744, 30651, 31979, 30417, 31506, 30805, 30210, 233, 181, 140, 233, 186, 131, 30503, 31579, 235, 131, 134, 30267], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30287, 30346, 236, 155, 183, 233, 179, 151, 31076, 30908, 30210, 31900, 30267], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 2, training_nums = 1237, num_steps = 618, warmup_steps = 1000, eval_steps = 77, save_steps = 77
world_size = 2
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [29871, 30810, 31882, 30630, 30210, 31900, 30548, 30214, 30810, 31882, 20778, 30210, 31969, 30745], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30417, 30287, 31893, 31900, 232, 146, 174, 232, 132, 157, 31811, 30413, 31174, 31475], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [29871, 30470, 235, 192, 190, 30594, 235, 144, 149, 31932, 234, 142, 133, 234, 134, 176, 31138, 30214, 30744, 30651, 31979, 30417, 31506, 30805, 30210, 233, 181, 140, 233, 186, 131, 30503, 31579, 235, 131, 134, 30267], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30287, 30346, 236, 155, 183, 233, 179, 151, 31076, 30908, 30210, 31900, 30267], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [29871, 30810, 31882, 30630, 30210, 31900, 30548, 30214, 30810, 31882, 20778, 30210, 31969, 30745], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30417, 30287, 31893, 31900, 232, 146, 174, 232, 132, 157, 31811, 30413, 31174, 31475], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [29871, 30470, 235, 192, 190, 30594, 235, 144, 149, 31932, 234, 142, 133, 234, 134, 176, 31138, 30214, 30744, 30651, 31979, 30417, 31506, 30805, 30210, 233, 181, 140, 233, 186, 131, 30503, 31579, 235, 131, 134, 30267], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [29871, 30287, 30346, 236, 155, 183, 233, 179, 151, 31076, 30908, 30210, 31900, 30267], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1237, num_steps = 1236, warmup_steps = 1000, eval_steps = 154, save_steps = 154
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
unk token: <unk>, unk token id: 0, pad token: <unk>, pad token id: 0
Eval tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Eval tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 32131, 32789, 54755, 54653, 31123, 32131, 64709, 33273], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [30910, 34410, 54755, 35528, 41405, 35445], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1]}
Train tokenized example: {'input_ids_chosen': [30910, 48421, 56598, 55632, 56206, 55002, 54597, 31123, 31672, 36563, 54729, 31762, 39740, 54542, 32450, 31155], 'attention_mask_chosen': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids_rejected': [34346, 54613, 55761, 54802, 54591, 33673, 54755, 31155], 'attention_mask_rejected': [1, 1, 1, 1, 1, 1, 1, 1]}
num_gpus = 1, training_nums = 1985, num_steps = 1984, warmup_steps = 1000, eval_steps = 248, save_steps = 248
world_size = 1
